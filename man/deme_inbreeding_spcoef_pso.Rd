% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main_pso.R
\name{deme_inbreeding_spcoef_pso}
\alias{deme_inbreeding_spcoef_pso}
\title{Identify Deme Inbreeding Spatial Coefficients in Continuous Space with
Particle Swarm Meta-Optimization}
\usage{
deme_inbreeding_spcoef_pso(
  discdat,
  m_lowerbound = 1e-10,
  m_upperbound = Inf,
  fi_lowerinit = 0.001,
  fi_upperinit = 0.3,
  flearn_lowerinit = 1e-10,
  flearn_upperinit = 0.01,
  mlearn_lowerinit = 1e-15,
  mlearn_upperinit = 1e-08,
  c1 = 2,
  c2 = 2,
  w = 0.73,
  b1 = 0.9,
  b2 = 0.999,
  e = 1e-08,
  steps = 1000,
  searchsteps = 100,
  swarmsteps = 50,
  swarmsize = 25,
  thin = 1,
  normalize_geodist = TRUE,
  report_sd_progress = TRUE,
  report_fd_progress = TRUE,
  return_verbose = FALSE
)
}
\arguments{
\item{discdat}{dataframe; The genetic-geographic data by deme (K)}

\item{m_lowerbound}{double; lower limit value for the global "m" parameter; will use a reflected normal within the gradient descent algorithm to adjust any aberrant values}

\item{m_upperbound}{double; upper limit value for the global "m" parameter; will use a reflected normal within the gradient descent algorithm to adjust any aberrant values}

\item{fi_lowerinit}{double; The initial deme-inbreeding parameter lower-bound to parameterize
each swarm-particle (\eqn{a}), such that starting deme-inbreeding estimates are drawn from
a uniform distribution \eqn{f = U_{a,b} }}

\item{fi_upperinit}{double; As above, the initial deme-inbreeding parameter upper-bound to parameterize
each swarm-particle (\eqn{b}).}

\item{flearn_lowerinit}{double; The initial deme-inbreeding learning-rate lower-bound to parameterize
each swarm-particle's convergence to the \eqn{f} parameter (\eqn{a} draw from the unifrom \eqn{f = U_{a,b} }).}

\item{flearn_upperinit}{double; As above, the initial deme-inbreeding learning-rate upper-bound to parameterize
each swarm-particle (\eqn{b}).}

\item{mlearn_lowerinit}{double; similar to before, the initial migration learning-rate lower-bound to parameterize
each swarm-particle's convergence to the \eqn{m} parameter (\eqn{a} draw from the unifrom \eqn{m = U_{a,b} }).}

\item{mlearn_upperinit}{double; As above, the initial migration learning-rate upper-bound to parameterize
each swarm-particle (\eqn{b}).}

\item{c1}{}

\item{c2}{}

\item{w}{}

\item{b1}{double; Exponential decay rates for the first moment estimate}

\item{b2}{double; Exponential decay rates for the second moment estimate}

\item{e}{double; Epsilon (error) for stability in the Adam optimization algorithm}

\item{steps}{integer; the number of "steps" as we move down the gradient}

\item{searchsteps}{}

\item{swarmsteps}{}

\item{swarmsize}{}

\item{thin}{integer; the number of "steps" to keep as part of the output (i.e. if the user specifies 10, every 10th iteration will be kept)}

\item{normalize_geodist}{boolean; whether geographic distances between demes should be normalized (i.e. Min-Max Feature Scaling: \eqn{X' = \frac{X - X_{min}}{X_{max} - X_{min}} }, which places the geodistances on the scale to \eqn{[0-1]}). Helps increase model stability at the expense of complicating the interpretation of the migration rate parameter.}

\item{report_sd_progress}{boolean; search chain}

\item{report_fd_progress}{boolean; final chain}

\item{return_verbose}{boolean; whether the inbreeding coefficients and migration rate should be returned for every iteration or
only for the final iteration. User will typically not want to store every iteration, which can be memory intensive}
}
\description{
The Particle Swarm Optimization is a meta-optimization (meta-heuristic) approach that attempts to find optimal
start parameters for the user to avoid a grid-search approach as would be best practices for fine-tuning the gradient descent
approach.
}
\references{
Clerc, M., and J. Kennedy. The Particle Swarm — Explosion, Stability, and Convergence in a Multidimensional Complex Space. IEEE Transactions on Evolutionary Computation 6, no. 1 (February 2002): 58–73. Y. H. Shi and R. C. Eberhart, “A modified particle swarm optimizer,” in Proceedings of the IEEE International Conferences on Evolutionary Computation, pp. 69–73, Anchorage, Alaska, USA, May 1998.
}
